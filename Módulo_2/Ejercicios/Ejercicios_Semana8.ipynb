{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "turkish-walker",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ejercicios semana 8 - Clasificación"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "noted-rover",
   "metadata": {},
   "source": [
    "El objetivo de los ejercicios de esta semana es integrar lo que aprendimos de modelos para clasificación al flujo de trabajo que venimos desarrollando: separación de conjunto de entrenamiento y testeo; preparación de los datos; diseño de características (polinomiales); determinación de hiperparámetros a partir de validación cruzada; evaluación final con el conjunto de testeo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "center-coating",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Funciones útiles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "turkish-gather",
   "metadata": {},
   "source": [
    "Volvemos a definir las funciones que usamos para los notebooks de esta semana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52437650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "def plot_clasi(x, t, ws, labels=[], xp=[-1,1], spines='zero',\n",
    "               equal=True, join_centers=False, margin=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Plot results of linear classification problems.\n",
    "    :param np.array x: Data matrix\n",
    "    :param np.array t: Label vector.\n",
    "    :param list or tuple ws: list with fitted paramter vector of models, one element per model\n",
    "    :param tuple xp: start and end x-coordinates of decision boundaries and\n",
    "                     margins.\n",
    "    :param str or None spines: whether the spines go through zero. If None,\n",
    "                               the default behaviour is used.\n",
    "    :param bool equal: whether to use equal axis aspect (default=True;\n",
    "                       recomended to see the parameter vector normal to\n",
    "                       boundary)\n",
    "    :param bool join_centers: whether to draw lines between classes centres.\n",
    "    :param None or tuple margin: tupler of booleans that define whether\n",
    "                                 to plot margin for each model being plotted.\n",
    "                                 If None, False for all models.\n",
    "    \"\"\"\n",
    "    assert len(labels) == len(ws) or len(labels) == 0\n",
    "\n",
    "    if margin is None:\n",
    "        margin = [False] * len(ws)\n",
    "    else:\n",
    "        margin = np.atleast_1d(margin)\n",
    "    assert len(margin) == len(ws)\n",
    "\n",
    "    if len(labels) == 0:\n",
    "        labels = np.arange(len(ws)).astype('str')\n",
    "\n",
    "    # Agregemos el vector al plot\n",
    "    fig = plt.figure(figsize=(9, 7))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    xc1 = x[t == np.unique(t).max()]\n",
    "    xc2 = x[t == np.unique(t).min()]\n",
    "\n",
    "    ax.plot(*xc1.T, 'or', mfc='None', label='C1')\n",
    "    ax.plot(*xc2.T, 'ob', mfc='None', label='C2')\n",
    "\n",
    "    for i, w in enumerate(ws):\n",
    "        # Separa el sesgo del resto de los pesos\n",
    "        thr = -w[0]\n",
    "        w = w[1:]\n",
    "        # Calcula la norma del vector\n",
    "        wnorm = np.sqrt(np.sum(w**2))\n",
    "\n",
    "        # Ploteo vector de pesos\n",
    "        ax.quiver(0, thr/w[1], w[0]/wnorm, w[1]/wnorm,\n",
    "                  color='C{}'.format(i+2), scale=10, label=labels[i],\n",
    "                  zorder=10)\n",
    "\n",
    "        # ploteo plano perpendicular\n",
    "        xp = np.array(xp)\n",
    "        yp = (thr - w[0]*xp)/w[1]\n",
    "\n",
    "        plt.plot(xp, yp, '-', color='C{}'.format(i+2))\n",
    "\n",
    "        # ploteo el margen (para SVC)\n",
    "        if margin[i]:\n",
    "            for marg in [-1, 1]:\n",
    "                ym = yp + marg/w[1]\n",
    "                plt.plot(xp, ym, ':', color='C{}'.format(i+2))\n",
    "\n",
    "    if join_centers:\n",
    "        # Ploteo línea que une centros de los conjuntos\n",
    "        mu1 = xc1.mean(axis=1)\n",
    "        mu2 = xc2.mean(axis=1)\n",
    "        ax.plot([mu1[0], mu2[0]], [mu1[1], mu2[1]], 'o:k', mfc='None', ms=10)\n",
    "\n",
    "    ax.legend(loc=0, fontsize=12)\n",
    "    if equal:\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "    if spines is not None:\n",
    "        for a in ['left', 'bottom']:\n",
    "            ax.spines[a].set_position('zero')\n",
    "        for a in ['top', 'right']:\n",
    "            ax.spines[a].set_visible(False)\n",
    "\n",
    "    for k in kwargs:\n",
    "        print(k, kwargs[k])\n",
    "        getattr(ax, 'set_'+k)(kwargs[k])\n",
    "\n",
    "    return\n",
    "\n",
    "def plot_fundec(fitter, x, t):\n",
    "\n",
    "    plt.figure(figsize=(9, 7))\n",
    "\n",
    "    xx, yy = np.meshgrid(np.linspace(x[:, 0].min()-1, x[:, 0].max()+1, 200),\n",
    "                            np.linspace(x[:, 1].min()-1, x[:, 1].max()+1, 200))\n",
    "\n",
    "    # evaluate decision function\n",
    "    try:\n",
    "        Z = fitter.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "        vcenter = 0.5\n",
    "        name = 'Probabilidad'\n",
    "    except AttributeError:\n",
    "        Z = fitter.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        vcenter = 0.0\n",
    "        name = 'Función de decisión'\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # veamos la función de decisión y la frontera de decisión\n",
    "    mynorm = colors.TwoSlopeNorm(vmin=Z.min(), vmax=Z.max(), vcenter=vcenter)\n",
    "    pme = plt.pcolormesh(xx, yy, Z, cmap=plt.cm.RdBu_r, norm=mynorm, shading='auto')\n",
    "    plt.colorbar(label= name)\n",
    "\n",
    "    plt.contour(xx, yy, Z, [vcenter,], colors='0.5', zorder=1)\n",
    "    if name == 'Probabilidad':\n",
    "        plt.contour(xx, yy, Z, [vcenter - 0.45, vcenter + 0.45],\n",
    "                    colors='white', linestyles='dashed', zorder=1)\n",
    "\n",
    "    xc1 = x[t == np.unique(t.flatten()).max()]\n",
    "    xc2 = x[t == np.unique(t.flatten()).min()]\n",
    "\n",
    "    plt.plot(*xc1.T, 'or', mfc='None', label='C1')\n",
    "    plt.plot(*xc2.T, 'ob', mfc='None', label='C2')\n",
    "\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.axis('tight')\n",
    "\n",
    "    return pme"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "pharmaceutical-airfare",
   "metadata": {},
   "source": [
    "## Café con dos medialunas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "christian-raise",
   "metadata": {},
   "source": [
    "Vamos a trabajar con un conjunto de datos sintéticos que puede armarse con la función de `sklearn` llamada `make_moons`.\n",
    "\n",
    "Vamos a generar el dataset y visualizarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "datos, t = make_moons(n_samples=500, noise=0.15, random_state=20230628)\n",
    "plot_clasi(datos, t, ws=[])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af9ecf63",
   "metadata": {},
   "source": [
    "Este conjunto tiene dos variables $(x_1, x_2)$, que están contenidas en la varible `datos` que recién definimos. Además, el conjunto está etiquetado (rojo o azul; 0 o 1), y el valor de la etiqueta está contenido en la variable `t` (de *target*). \n",
    "\n",
    "Como se pueden imaginar, este conjunto no es linealmente separable si usamos estas dos variables separar con un modelo lineal, pero podemos generar nuevas características a partir de estas con `PolynomialFeatures` e intentar separar el conjunto.\n",
    "\n",
    "Pero antes de eso vamos a separar el conjunto."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c92ed231",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "  - Separen al conjunto de datos original (`datos`) en un conjunto de entrenamiento (80%) y otro de testeo (20%). Agreguen al nombre de las variables `_train` y `_test` para diferenciarlas. \n",
    "\n",
    "**Sugerencia**: verifiquen que los arreglos resultantes tienen el tamaño y forma que esperan mirando el atributo `shape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44227699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4461709f",
   "metadata": {},
   "source": [
    "Ahora empiezan las decisiones. Elijan un algoritmo (Perceptrón o Regresión Logística) y un tipo de penalización (L1 o L2) con el que vamos a trabajar en esta primera parte.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd52b8e0",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    " \n",
    "Preparen un pipeline que estandarice los datos, genere features polinomiales de algún grado (empecemos con `degree=2`) y los use para ajustar el modelo elegido con una dada constante de regularización.\n",
    "\n",
    "**Ayuda**: recuerden que para armar el pipeline, hay que dar una lista (es decir, `[ ... ]`) de tuplas (es decir `( ... )`) con el nombre de los pasos y la función o clase correspondiente. Ver ejemplo.\n",
    "\n",
    "**Ayuda2**: recuerden que cuando se combina con features polinomiales hay que setear `fit_intercept=False` en el clasificador (a menos que usen `include_bias=False` en `PolynomialFeatures`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b619a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "\n",
    "mi_pipe = Pipeline([('estandariza', ...),\n",
    "                    ('poly', ...),\n",
    "                    ('clasi', ...)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8e72e78",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "Ajusten los parámetros del clasificador usando el pipeline del paso anterior con el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f049f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "825dbd81",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "Impriman en pantalla los coeficientes encontrados. Recuerden que pueden acceder a cada paso del pipeline como si fuera un diccionario de python. P.ej., si llamé `'clasi'` al último paso, puedo usar `mi_pipe['clasi']` para acceder al clasificador.\n",
    "\n",
    "Respondan: ¿cuántos coeficientes hay? ¿tiene sentido con la cantidad de grados elegido para el PolynomialFeatures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b8e687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ad05d0e",
   "metadata": {},
   "source": [
    "## Ejercicio 5\n",
    "\n",
    "Usen la función `plot_fundec` para ver la frontera de decisión. \n",
    "    \n",
    "Evalúen si el grado del polinomio es el adecuado. Si no, súbanlo o bájenlo hasta encontrar algo que a ojo les resulte que funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985aaa10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c21db5b0",
   "metadata": {},
   "source": [
    "## Ejercicio 6\n",
    "\n",
    "Evalúen el desempeño del algoritmo en base a sus métricas de exactitud, precisión y exhaustividad. También calculen la matriz de pérdida (todo en el conjunto de entrenamiento)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f79f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3db7b93",
   "metadata": {},
   "source": [
    "## Ejercicio 7 \n",
    "\n",
    "Usar `GridSearchCV` para buscar valores óptimos de los hiperparámetros: grado de la transformación polinomial (`degree`) y constante de regularización (`C` o `alpha`, según qué modelo hayan elegido). ¿Cuáles son los mejores parámetros?\n",
    "\n",
    "**Recordatorio**. Cuando se usa `GridSearchCV` con un pipeline, el nombre de los parámetros hay que escribirlos como 'NOMBREDELPASO__NOMBREDELPARAMETRO'. Por ejemplo, para el paso de transformación polinomial, el grado es `poly__degree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ef3cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "201562aa",
   "metadata": {},
   "source": [
    "## Ejercicio 8\n",
    "\n",
    "Usar `plot_fundec` con el mejor estimador obtenido a partir de la búsqueda. Calcular las métricas de arriba, pero esta vez usando `cross_val_predict` para obtener las predicciones del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca8f10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f28196f",
   "metadata": {},
   "source": [
    "## Ejercicio 9\n",
    "\n",
    "Evalúen ahora el algoritmo tuneado en el conjunto de testeo. Comparen con los resultados del ejericio anterior. ¿Qué valor de exactitud o F1 score dirían que tiene el algoritmo entrenado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26916c14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf-mac')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-showcode": false,
  "vscode": {
   "interpreter": {
    "hash": "2b7aa682480b82eb27ca7b5ecfebdb0027bb2a276e6bdff64c1ddeab03557e9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
